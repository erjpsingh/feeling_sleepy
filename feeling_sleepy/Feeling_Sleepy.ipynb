{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Feeling Sleepy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mandatory Imports \n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object for web cam\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# infonite loop to read the feed\n",
    "\n",
    "while True :\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('name_frame', frame)\n",
    "    \n",
    "    if 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### this one works \n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('gray',gray)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function uses two classifiers , first to detect face and then to detect eyes in face\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# multiple cascades: https://github.com/Itseez/opencv/tree/master/data/haarcascades\n",
    "\n",
    "#https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_eye.xml\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this one works for blink detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n"
     ]
    }
   ],
   "source": [
    " import numpy as np  \n",
    " import cv2  \n",
    " import dlib  \n",
    " import datetime   \n",
    " from scipy.spatial import distance as dist  \n",
    "   \n",
    " PREDICTOR_PATH = \"/home/jasp/PycharmProjects/feeling_sleepy/shape_predictor_68_face_landmarks.dat\"  \n",
    "   \n",
    " FULL_POINTS = list(range(0, 68))  \n",
    " FACE_POINTS = list(range(17, 68))  \n",
    "   \n",
    " JAWLINE_POINTS = list(range(0, 17))  \n",
    " RIGHT_EYEBROW_POINTS = list(range(17, 22))  \n",
    " LEFT_EYEBROW_POINTS = list(range(22, 27))  \n",
    " NOSE_POINTS = list(range(27, 36))  \n",
    " RIGHT_EYE_POINTS = list(range(36, 42))  \n",
    " LEFT_EYE_POINTS = list(range(42, 48))  \n",
    " MOUTH_OUTLINE_POINTS = list(range(48, 61))  \n",
    " MOUTH_INNER_POINTS = list(range(61, 68))  \n",
    "   \n",
    " EYE_AR_THRESH = 0.25  \n",
    " EYE_AR_CONSEC_FRAMES = 3  \n",
    "   \n",
    " COUNTER_LEFT = 0  \n",
    " TOTAL_LEFT = 0  \n",
    "   \n",
    " COUNTER_RIGHT = 0  \n",
    " TOTAL_RIGHT = 0  \n",
    "   \n",
    " def eye_aspect_ratio(eye):  \n",
    "   # compute the euclidean distances between the two sets of  \n",
    "   # vertical eye landmarks (x, y)-coordinates  \n",
    "   A = dist.euclidean(eye[1], eye[5])  \n",
    "   B = dist.euclidean(eye[2], eye[4])  \n",
    "   \n",
    "   # compute the euclidean distance between the horizontal  \n",
    "   # eye landmark (x, y)-coordinates  \n",
    "   C = dist.euclidean(eye[0], eye[3])  \n",
    "   \n",
    "   # compute the eye aspect ratio  \n",
    "   ear = (A + B) / (2.0 * C)  \n",
    "   \n",
    "   # return the eye aspect ratio  \n",
    "   return ear  \n",
    "   \n",
    " detector = dlib.get_frontal_face_detector()  \n",
    "   \n",
    " predictor = dlib.shape_predictor(PREDICTOR_PATH)  \n",
    "   \n",
    " # Start capturing the WebCam  \n",
    " video_capture = cv2.VideoCapture(1) \n",
    "   \n",
    " while True:  \n",
    "   ret, frame = video_capture.read()  \n",
    "   \n",
    "   if ret:  \n",
    "     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  \n",
    "   \n",
    "     rects = detector(gray, 0)  \n",
    "   \n",
    "     for rect in rects:  \n",
    "       x = rect.left()  \n",
    "       y = rect.top()  \n",
    "       x1 = rect.right()  \n",
    "       y1 = rect.bottom()  \n",
    "   \n",
    "       landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])  \n",
    "   \n",
    "       left_eye = landmarks[LEFT_EYE_POINTS]  \n",
    "       right_eye = landmarks[RIGHT_EYE_POINTS]  \n",
    "   \n",
    "       left_eye_hull = cv2.convexHull(left_eye)  \n",
    "       right_eye_hull = cv2.convexHull(right_eye)  \n",
    "       cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1)  \n",
    "       cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)  \n",
    "   \n",
    "       ear_left = eye_aspect_ratio(left_eye)  \n",
    "       ear_right = eye_aspect_ratio(right_eye)  \n",
    "   \n",
    "       cv2.putText(frame, \"E.A.R. Left : {:.2f}\".format(ear_left), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)  \n",
    "       cv2.putText(frame, \"E.A.R. Right: {:.2f}\".format(ear_right), (300, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)  \n",
    "   \n",
    "       if ear_left < EYE_AR_THRESH:  \n",
    "         COUNTER_LEFT += 1  \n",
    "       else:  \n",
    "         if COUNTER_LEFT >= EYE_AR_CONSEC_FRAMES:  \n",
    "           TOTAL_LEFT += 1  \n",
    "           print(\"Left eye winked\")  \n",
    "         COUNTER_LEFT = 0  \n",
    "   \n",
    "       if ear_right < EYE_AR_THRESH:  \n",
    "         COUNTER_RIGHT += 1  \n",
    "       else:  \n",
    "         if COUNTER_RIGHT >= EYE_AR_CONSEC_FRAMES:  \n",
    "           TOTAL_RIGHT += 1  \n",
    "           print(\"Right eye winked\")  \n",
    "         COUNTER_RIGHT = 0  \n",
    "   \n",
    "     cv2.putText(frame, \"Wink Left : {}\".format(TOTAL_LEFT), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)  \n",
    "     cv2.putText(frame, \"Wink Right: {}\".format(TOTAL_RIGHT), (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)  \n",
    "     cv2.putText(frame,\"Time : {}\".format(datetime.datetime.now()),(10,90),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "     cv2.imshow(\"Faces found\", frame) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "   import datetime\n",
    "   ch = 0xFF & cv2.waitKey(1)  \n",
    "   \n",
    "   if ch == ord('q'):  \n",
    "     break  \n",
    "   \n",
    " cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-21 11:26:46.331164\n"
     ]
    }
   ],
   "source": [
    "# playing wit time , need to get time in seconds \n",
    "\n",
    "import datetime\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
